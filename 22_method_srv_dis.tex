When implementing a microservice architecture the amount and scale of services can become a big burden when it comes to coupling the services.
If hooking services together implies manual labor to put IP addresses into config files, the scalability of the system is going to be fairly limited.
Instead the system should propose its capabilities and discover other services automatically.

The used implementation starts as a set of bash scripts updating etcd (a distributed key/value store). This key/valiue store was used by SkyDNS\footnote{\Mundus~\url{https://github.com/skynetservices/skydns1}}, which exposes entries
over a DNS interface and thus, made the coupling of distributed services relatively easy. To dynamically create configuration files a tool called confd emerged, which consumes
etcd and produces configuration files from templates if a watched value changes.

A more holistic tool to deal with this set of functionality is Consul. It combines a key/value store, service checks, a DNS interface and an RESTful API
in one golang binary, which is easy to manage.

\autoref{lst:srv_json} describes a service, including attributes and checks to determine the state of the service based on the return code of the script (like NAGIOS does). 

\begin{lstlisting}[language=bash,
    caption={Service definition within consul. If the keyword open is not find within the nmap output the service is marked WARNING},
    label={lst:srv_json}]

{
  "service": {
    "name": "nginx",
    "port": 80,
    "check": {
      "script": "nmap 127.0.0.1 -p80|grep open",
      "interval": "10s"
    }
  }
}
\end{lstlisting}

If the check indicates the service is usable, the service is exposed via an DNS interface.
Thus the service can be reached via the \gls{fqdn} (\glsdesc{fqdn}) \lstinline{<service-name>.service.consul} as shown in \autoref{lst:dig_nginx}.
\begin{lstlisting}[language=bash,
    caption={Exposure of services via DNS.},
    label={lst:dig_nginx}]
$ dig SRV +short nginx.service.consul
1 1 80 nginx.node.qnib.consul.
\end{lstlisting}

The ablility to reference a service via DNS is extremely helpful, since name resolving works system-wide. Instead of static IP address,
configuration holds the \gls{fqdn} to describe a dependency to a different node. Furthermore the complete tooling is going to work as well; checking network connectivity is as
simple as \lstinline{pinging} the \gls{fqdn}.

\autoref{lst:curl_nginx} shows an additional RESTful API to access information as JSON blobs.

\begin{lstlisting}[language=bash,
    caption={Exposure of services via RESTful API.},
    label={lst:curl_nginx}]
$ export URL=localhost:8500/v1/catalog/service
$ curl -s $URL/nginx|python -m json.tool
[
    {
        "Address": "172.17.0.6",
        "Node": "nginx",
        "ServiceAddress": "",
        "ServiceID": "nginx",
        "ServiceName": "nginx",
        "ServicePort": 80,
        "ServiceTags": null
    }
]
\end{lstlisting}
This provides the ability to use this information in external scripts or use the rich ecosystem that has already build up around service discovery.

Since QNIBMon aims to be modular and flexible in its composition, a service discovery mechanism which is able to dynamically update itself is crucial to the success of the framework.
